{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Variational Autoencoder\n",
    "======================\n",
    "Classe de modelos generativos que combina conceitos de aprendizado profundo e estatística bayesiana para aprender representações latentes contínuas de dados, permitindo a geração de novos exemplos semelhantes aos dados de treinamento.\n",
    "\n",
    "1 Autoencoder\n",
    "--------------\n",
    "\n",
    "Um autoencoder tradicional é uma rede neural que consiste em duas partes principais:\n",
    "\n",
    "* Encoder: Mapeia os dados de entrada para um espaço latente de dimensão inferior.\n",
    "* Decoder: Reconstrói os dados originais a partir da representação latente.\n",
    "\n",
    "O objetivo do autoencoder é comprimir os dados e, em seguida, reconstruí-los da forma mais fiel possível.\n",
    "\n",
    "**Limitações do autoencoder**\n",
    "\n",
    "* Embora um autoencoder possa aprender boas representações latentes dos dados, ele não é projetado para gerar novas amostras do espaço latente. A representação latente pode ser irregular, e pequenas variações no espaço latente podem levar a grandes alterações nas amostras reconstruídas.\n",
    "\n",
    "2 Variabilidade (probabilidade)\n",
    "--------------------------------\n",
    "\n",
    "O VAE introduz um componente probabilístico no processo, onde em vez de mapear uma entrada para um único ponto no espaço latente, ele mapeia para uma distribuição (tipicamente uma distribuição normal).\n",
    "\n",
    "Em termos práticos, o encoder de um VAE não gera diretamente a representação latente (`z`), mas gera parâmetros de uma distribuição (a média $\\mu$ - `mu` e o log da variância `logvar`), de onde `z` será amostrado.\n",
    "\n",
    "3 Reparametrização\n",
    "-------------------\n",
    "Para garantir que o processo de amostragem de `z` seja diferenciável (necessário para treinar a rede usando retropropagação), o VAE utiliza um truque chamado reparametrização.\n",
    "O vetor latente `z` é obtido combinando a média `mu`, a variância `logvar`, e um vetor de ruído `epsilon`:\n",
    "\n",
    "$ z = \\mu + \\sigma * \\epsilon$\n",
    "\n",
    "onde,\n",
    "\n",
    "* sigma é a raiz quadrada da variância;7\n",
    "* epsilon é amostrado de uma distribuição normal padrão.\n",
    "\n",
    "\n",
    "4 Decoder como gerador\n",
    "----------------------\n",
    "O decoder do VAE recebe `z` (amostrado da distribuição latente) e tenta reconstruir a entrada original. Como `z` é amostrado de uma distribuição normal, podemos amostrar diferentes `z` para gerar novas amostras, o que transforma o decoder em um gerador.\n",
    "\n",
    "5 Função de perda do VAE\n",
    "-----------------------\n",
    "\n",
    "A função de perda do VAE é composta por dois termos principais:\n",
    "\n",
    "* **Reconstrução (Reconstruction Loss):** Mede o quão bem o decoder consegue reconstruir a entrada original a partir do vetor `z`. Isso geralmente é calculado como a entropia cruzada entre os dados reais e os reconstruídos.\n",
    "* **Divergência de Kullback-Leibler (KL Divergence):** Mede o quão próxima a distribuição latente aprendida (definida por `mu` e `logvar`) está de uma distribuição normal padrão (distribuição-alvo). Essa regularização incentiva o espaço latente a ser contínuo e permite a geração de novas amostras ao decodificar `z` amostrados de uma distribuição normal padrão.\n",
    "\n",
    "6 Vantagens do VAE\n",
    "-------------------\n",
    "\n",
    "* **Geração de Dados:** O VAE pode gerar novos dados que se parecem com os dados de treinamento, mas são amostras novas.\n",
    "* **Espaço Latente Contínuo:** O espaço latente aprendido pelo VAE é contínuo, o que significa que pequenas variações em z resultam em pequenas variações nos dados gerados.\n",
    "* **Interpolação:** Por causa da regularização do espaço latente, podemos interpolar entre diferentes pontos latentes e gerar transições suaves entre os exemplos gerados.\n"
   ],
   "id": "e55b48057d1d96ba"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T09:59:45.065232Z",
     "start_time": "2024-09-02T09:59:42.451293Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Espaço latente\n",
    "===============\n",
    "\n",
    "Espaço latente é um espaço de dimensão reduzida onde os dados são representados de maneira compacta e significativa. Os vetores latentes são pontos neste espaço. Cada vetor latente pode ser mapeado para uma amostra no espaço original dos dados (por exemplo, uma imagem, texto ou som)."
   ],
   "id": "b999aedeeb4307ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Vetor latente\n",
    "______________\n",
    "\n",
    "1. **Representação Compacta:** Um vetor latente é uma representação compacta e densa de uma amostra. Por exemplo, uma imagem de alta resolução pode ser representada por um vetor latente de dimensão muito menor do que o número total de pixels da imagem.\n",
    "\n",
    "2. **Dimensionalidade Reduzida:** O vetor latente possui uma dimensionalidade menor em comparação com os dados originais, o que ajuda a capturar os padrões mais importantes dos dados. Isso significa que o vetor latente retém as informações mais relevantes de maneira condensada.\n",
    "\n",
    "3. **Entrada para Modelos Geradores:** Em modelos como GANs, o vetor latente serve como entrada para o gerador, que transforma esse vetor em uma amostra do espaço original (como uma imagem, som ou texto). Diferentes vetores latentes podem gerar diferentes amostras, e pequenas mudanças no vetor latente podem resultar em variações na amostra gerada."
   ],
   "id": "d787decbcedb4380"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:59:50.726797Z",
     "start_time": "2024-09-02T09:59:50.722227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parâmetros\n",
    "latent_dim = 20  # Dimensão do espaço latente\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "img_shape = (1, 28, 28)"
   ],
   "id": "64794db236bd3a48",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:59:53.081841Z",
     "start_time": "2024-09-02T09:59:53.076762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformação dos dados\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ],
   "id": "c9306f94ea4f7e7c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T09:59:55.708187Z",
     "start_time": "2024-09-02T09:59:55.630397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carregar dataset MNIST\n",
    "dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "9d4617e9a4a2947d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:00:03.784024Z",
     "start_time": "2024-09-02T10:00:03.775239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir a arquitetura do VAE\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Camadas para a média e log variância\n",
    "        self.fc_mu = nn.Linear(100, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(100, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 28 * 28),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Unflatten(1, img_shape)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ],
   "id": "61590ac65c5adc5f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Divergência de Kullback-Leibler\n",
    "--------------------------------\n",
    "\n",
    "A divergência de Kullback-Leibler (KL) é uma medida da teoria da informação que quantifica o quanto uma distribuição de probabilidade diverge de uma segunda distribuição de referência. Também é conhecida como entropia relativa entre duas distribuições.\n",
    "\n",
    "Dadas duas distribuições de probabilidade $P$ e $Q$ definidas sobre o mesmo espaço de probabilidade, a divergência KL de $Q$ para $Q$ é definida como:\n",
    "\n",
    "$$D_{KL}(P \\parallel Q) = \\sum_{x} P(x) \\log \\frac{P(x)}{Q(x)}$$\n",
    "\n",
    "Para distribuições contínuas, a soma é substituída por uma integral:\n",
    "\n",
    "$$D_{KL}(P \\parallel Q) = \\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} \\, dx$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "* $P(x)$ é a verdadeira distribuição de probabilidade dos dados (também chamada de distribuição alvo).\n",
    "* $Q(x)$ é a distribuição aproximada (também chamada de distribuição do modelo).\n",
    "\n",
    "Interpretação\n",
    "------------\n",
    "\n",
    "* **A divergência KL é assimétrica:** $D_{KL} (P || Q)$ não é igual a $D_{KL} (Q || P)$, ou seja, a divergência de $P$ para $Q$ não é a mesma de $Q$ para $P$;\n",
    "* **Não-negativa:** $D_{KL} (P || Q) \\geq 0$  para todas as distribuições $P$ e $Q$, sendo igual a zero se e somente se $P = Q$ quase em toda parte;\n",
    "* **Não é uma verdadeira distância:** Como a divergência KL é assimétrica, ela não satisfaz a desigualdade triangular e, portanto, não é uma métrica ou distância verdadeira.\n",
    "\n",
    "Uso\n",
    "-------\n",
    "A divergência KL é amplamente utilizada em várias áreas, incluindo:\n",
    "\n",
    "* **Aprendizado de Máquina:** Em algoritmos como Variational Autoencoders (VAEs), onde é usada como um termo de regularização para medir o quão próxima a distribuição posterior aproximada está da distribuição a priori.\n",
    "* **Teoria da Informação:** Para quantificar a ineficiência de se assumir que a distribuição $Q$ é verdadeira quando a distribuição real é $P$.\n",
    "* **Processamento de Linguagem Natural:** Em tarefas como modelagem de tópicos ou na avaliação de quão semelhantes são duas distribuições.\n",
    "\n",
    "A divergência KL pode ser usada para comparar a similaridade entre duas distribuições, com uma divergência KL menor indicando que as distribuições são mais semelhantes."
   ],
   "id": "28d786716154e5b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:03:59.587766Z",
     "start_time": "2024-09-02T10:03:59.582201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função de perda (ELBO - Evidence Lower Bound)\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # Reconstruir x para o intervalo [0, 1]\n",
    "    x = (x + 1) / 2  # Ajusta os dados de entrada para o intervalo [0, 1]\n",
    "    \n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ],
   "id": "8ce2e3c8bcc7f3f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:04:02.902566Z",
     "start_time": "2024-09-02T10:04:02.893569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instanciar o modelo e definir o otimizador\n",
    "vae = VAE()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)"
   ],
   "id": "f3773dd37cd070aa",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:00:27.778265Z",
     "start_time": "2024-09-02T10:00:27.770379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função para treinar o VAE\n",
    "def train_vae(vae, dataloader, optimizer, epochs):\n",
    "    vae.train()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        for i, (data, _) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = vae(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {train_loss / len(dataloader.dataset):.4f}\")\n",
    "        \n",
    "        # Salvar algumas imagens geradas após cada época\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(64, latent_dim)\n",
    "            sample = vae.decode(z).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28), f\"images_vae/vae_sample_{epoch}.png\")"
   ],
   "id": "122cea24c91ce979",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:00:30.054716Z",
     "start_time": "2024-09-02T10:00:30.050123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar e criar o diretório 'images' se ele não existir\n",
    "if not os.path.exists('images_vae'):\n",
    "    os.makedirs('images_vae')"
   ],
   "id": "c8a8c21f99711f9e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T10:07:05.587481Z",
     "start_time": "2024-09-02T10:04:07.167391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treinar o VAE\n",
    "train_vae(vae, dataloader, optimizer, epochs)"
   ],
   "id": "31c9572c1f27ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Loss: 165.5711\n",
      "Epoch [2/10] Loss: 125.7749\n",
      "Epoch [3/10] Loss: 118.0250\n",
      "Epoch [4/10] Loss: 114.5662\n",
      "Epoch [5/10] Loss: 112.6322\n",
      "Epoch [6/10] Loss: 111.3212\n",
      "Epoch [7/10] Loss: 110.3092\n",
      "Epoch [8/10] Loss: 109.4944\n",
      "Epoch [9/10] Loss: 108.8132\n",
      "Epoch [10/10] Loss: 108.3451\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35fd1adebf2b0bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
